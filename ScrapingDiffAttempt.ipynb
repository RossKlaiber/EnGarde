import requests
import pandas as pd
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.support.ui import Select, WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By
import time

def extract_fencer_data(url):
    """
    Extracts static fencer details using requests and BeautifulSoup.
    """
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')
    
    data = {}
    data['FIE ID'] = url.rstrip('/').split('/')[-1]
    
    # Extract Name
    name_tag = soup.find('h1', class_='AthleteHero-fencerName')
    data['Name'] = name_tag.get_text(strip=True) if name_tag else None
    
    # Extract Image URL from inline style
    image_div = soup.find('div', class_='AthleteHero-fencerImage')
    if image_div and 'style' in image_div.attrs:
        style = image_div['style']
        start = style.find("url(")
        end = style.find(")", start)
        data['Image'] = style[start+4:end].strip('\'"')
    else:
        data['Image'] = None

    # Extract Weapon info
    weapon_tag = soup.find('div', class_='ProfileInfo-item')
    data['Weapon'] = weapon_tag.get_text(strip=True) if weapon_tag else None

    # Extract Category from dropdown
    category_select = soup.find('select', class_='js-athlete-dropdown-fencer-category')
    if category_select:
        selected_option = category_select.find('option', selected=True)
        data['Category'] = selected_option.get_text(strip=True) if selected_option else None
    else:
        data['Category'] = None

    # Extract Season (static from initial page load)
    season_select = soup.find('select', class_='js-season-dropdown')
    if season_select:
        selected_option = season_select.find('option', selected=True)
        data['Season'] = selected_option.get_text(strip=True) if selected_option else None
    else:
        data['Season'] = None

    data['Wins/losses'] = None  # Placeholder

    # Extract Rank
    rank_tag = soup.find('span', class_='ProfileInfo-rank')
    data['Rank'] = rank_tag.get_text(strip=True) if rank_tag else None

    # Extract Points (using string instead of text to avoid deprecation warnings)
    pts_label = soup.find(lambda tag: tag.name == 'span' and 'Pts' in tag.get_text())
    if pts_label:
        points_value = pts_label.find_next_sibling(string=True)
        data['Points'] = points_value.strip() if points_value else None
    else:
        data['Points'] = None

    # Extract Handedness (Left/Right)
    hand_label = soup.find(lambda tag: tag.name == 'span' and 'Hand' in tag.get_text())
    if hand_label:
        hand_value = hand_label.find_next_sibling(string=True)
        data['Left/Right'] = hand_value.strip() if hand_value else None
    else:
        data['Left/Right'] = None

    return data

def extract_competitions_last_five_seasons(url):
    """
    Uses Selenium to iterate over the past five season options from the dropdown,
    select each season, and extract competition data.
    Returns a list of dictionaries with keys: Year, Competition, and Link.
    """
    driver = webdriver.Chrome()  # Ensure your WebDriver is installed and in your PATH
    wait = WebDriverWait(driver, 10)
    driver.get(url)
    
    competitions_list = []
    
    # Wait for the season dropdown element.
    dropdown_elem = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "select.js-season-dropdown")))
    select = Select(dropdown_elem)
    
    # Process the first five options (assumed to be the most recent seasons).
    num_options = min(5, len(select.options))
    
    for i in range(num_options):
        # Re-locate the dropdown element to avoid stale element exceptions.
        dropdown_elem = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "select.js-season-dropdown")))
        select = Select(dropdown_elem)
        season_text = select.options[i].text.strip()  # e.g., "2022 / 2023"
        
        # Select the season option by its index.
        select.select_by_index(i)
        
        # Wait for the page to update.
        time.sleep(3)
        
        # Get updated page source and parse with BeautifulSoup.
        html = driver.page_source
        soup = BeautifulSoup(html, 'html.parser')
        
        results_container = soup.find('div', class_='js-athlete-results-tab-container')
        if results_container:
            # Find all competition links within the container.
            links = results_container.find_all('a', class_='Historial-link')
            for link in links:
                href = link.get('href')
                if href:
                    if href.startswith('/'):
                        href = 'https://fie.org' + href
                    # Extract the competition name from the first occurrence of the competition label.
                    competition_name_div = link.find("div", class_="Historial-label Historial-label--colorDark")
                    competition_name = competition_name_div.get_text(strip=True) if competition_name_div else ""
                    competitions_list.append({
                        "Year": season_text,
                        "Competition": competition_name,
                        "Link": href
                    })
        else:
            print(f"Competitions container not found for season {season_text}!")
    
    driver.quit()
    return competitions_list

# ---------------------------
# Main Execution
# ---------------------------
if __name__ == "__main__":
    url = 'https://fie.org/athletes/22439'
    
    # Extract static fencer data.
    fencer_data = extract_fencer_data(url)
    print("Fencer Data:")
    print(fencer_data)
    
    # Extract competitions data for the past five seasons.
    competitions_data = extract_competitions_last_five_seasons(url)
    
    # Create a single DataFrame with columns: Year, Competition, and Link.
    df_competitions = pd.DataFrame(competitions_data, columns=["Year", "Competition", "Link"])
    print("\nCombined Competitions DataFrame:")
    print(df_competitions)



def extract_diff_for_competition(competition_link, fencer_name):
    """
    Opens a competition page, clicks "Results" then "Pool Results",
    and uses the provided XPath to locate the table body.
    It then determines the column index for "Diff" by reading the header row,
    and finds the row containing fencer_name to extract the diff value.
    If not found or if pool results are unavailable, returns 0.
    """
    # Open Chrome normally (allowing the window to appear)
    driver = webdriver.Chrome()
    wait = WebDriverWait(driver, 10)
    try:
        driver.get(competition_link)
        time.sleep(2)  # Allow page to load

        # Click on the "Results" tab
        results_tab = wait.until(EC.element_to_be_clickable((By.XPATH, "//a[contains(text(), 'Results')]")))
        results_tab.click()
        time.sleep(5)

        # Click on the "Pool Results" sub-tab
        pool_tab = wait.until(EC.element_to_be_clickable((By.XPATH, "//a[contains(text(), 'Pools Results')]")))
        pool_tab.click()
        time.sleep(5)  # Wait for the pool results table to load

        # Wait for the table body to appear using the provided absolute XPath
        tbody_elem = wait.until(EC.presence_of_element_located((By.XPATH, 
            "/html/body/div[4]/div/div/div[2]/div[3]/div/div/div[3]/div[2]/div/table/tbody")))
        print (tbody_elem)
        
        # Get the header row to find the "Diff" column index
        header_elem = driver.find_element(By.XPATH, 
            "/html/body/div[4]/div/div/div[2]/div[3]/div/div/div[3]/div[2]/div/table/thead")
        header_cells = header_elem.find_elements(By.TAG_NAME, "th")
        diff_index = None
        for idx, cell in enumerate(header_cells):
            if "Diff." in cell.text:
                diff_index = idx
                break
        if diff_index is None:
            driver.quit()
            return "Dif not found"

        # Now get all rows from the tbody using Selenium
        rows = tbody_elem.find_elements(By.TAG_NAME, "tr")
        diff_value = 100
        found = False
        for row in rows:
            cells = row.find_elements(By.TAG_NAME, "td")
            # Check if any cell contains the fencer's name (case-insensitive)
            if any(fencer_name.lower() in cell.text.lower() for cell in cells):
                if len(cells) > diff_index:
                    diff_text = cells[diff_index].text.strip()
                    try:
                        diff_value = float(diff_text.replace(',', '.'))
                    except Exception as ex:
                        diff_value = 100
                found = True
                break
        driver.quit()
        return diff_value if found else 100
    except Exception as e:
        print("Error processing competition:", competition_link, e)
        driver.quit()
        return 100

# ---------------------------
# MAIN CODE (to be added after your existing code)
# ---------------------------
if __name__ == "__main__":
    # Assuming you already ran your code that defines:
    # - extract_fencer_data(url)
    # - extract_competitions_last_five_seasons(url)
    # and that you have variables 'fencer_data' and 'competitions_data'
    #
    # For example:
    # url = 'https://fie.org/athletes/22439'
    # fencer_data = extract_fencer_data(url)
    # competitions_data = extract_competitions_last_five_seasons(url)
    
    fencer_name = fencer_data.get("Name", "").strip()
    if not fencer_name:
        print("Fencer name not found. Exiting.")
        exit()

    # For each competition in your competitions_data list, extract the Diff value.
    for comp in competitions_data:
        diff = extract_diff_for_competition(comp["Link"], fencer_name)
        comp["Diff"] = diff
        print(f"Competition: {comp['Competition']} ({comp['Year']}): Diff = {diff}")

    # Create a single DataFrame from the competitions data.
    df_competitions = pd.DataFrame(competitions_data, columns=["Year", "Competition", "Link", "Diff"])
    print("\nCombined Competitions DataFrame with Diff scores:")
    print(df_competitions)

    # Group by Year (season) and create one DataFrame per season,
    # then sum the Diff scores for each season.
    total_diff_by_year = {}
    dfs_by_year = {}
    for year in df_competitions["Year"].unique():
        df_year = df_competitions[df_competitions["Year"] == year].reset_index(drop=True)
        dfs_by_year[year] = df_year
        total_diff_by_year[year] = df_year["Diff"].sum()
    
    # Optionally print each season's DataFrame.
    for year, df_year in dfs_by_year.items():
        print(f"\nDataFrame for season {year}:")
        print(df_year)
    
    # Create a list of total diff scores per season.
    total_diff_list = [total_diff_by_year[year] for year in df_competitions["Year"].unique()]
    print("\nTotal Diff scores per season (list):")
    print(total_diff_list)
